{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "\n",
    "from adjustText import adjust_text\n",
    "from scipy.stats import kendalltau, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"Chile\"\n",
    "year = 2021\n",
    "location_level = \"province\"\n",
    "\n",
    "colors = json.load(open(\"consts.json\", encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = {\n",
    "    \"DE ARICA Y PARINACOTA\": \"Región de Arica y Parinacota\",\n",
    "    \"DE TARAPACA\": \"Región de Tarapacá\",\n",
    "    \"DE ANTOFAGASTA\": \"Región de Antofagasta\",\n",
    "    \"DE ATACAMA\": \"Región de Atacama\",\n",
    "    \"DE COQUIMBO\": \"Región de Coquimbo\",\n",
    "    \"DE VALPARAISO\": \"Región de Valparaíso\",\n",
    "    \"METROPOLITANA DE SANTIAGO\": \"Región Metropolitana de Santiago\",\n",
    "    \"DEL LIBERTADOR GENERAL BERNARDO O'HIGGINS\": \"Región del Libertador Bernardo O'Higgins\",\n",
    "    \"DEL MAULE\": \"Región del Maule\",\n",
    "    \"DE ÑUBLE\": \"Región de Ñuble\",\n",
    "    \"DEL BIOBIO\": \"Región del Bío-Bío\",\n",
    "    \"DE LA ARAUCANIA\": \"Región de La Araucanía\",\n",
    "    \"DE LOS RIOS\": \"Región de Los Ríos\",\n",
    "    \"DE LOS LAGOS\": \"Región de Los Lagos\",\n",
    "    \"DE AYSEN DEL GENERAL CARLOS IBAÑEZ DEL CAMPO\": \"Región de Aysén del Gral.Ibañez del Campo\",\n",
    "    \"DE MAGALLANES Y DE LA ANTARTICA CHILENA\": \"Región de Magallanes y Antártica Chilena\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"geo_shapes/Chile_provinces.zip\")\n",
    "gdf[\"Provincia\"] = gdf[\"Provincia\"].str.upper().str.normalize(\"NFKD\").str.encode(\"ascii\", errors=\"ignore\").str.decode(\"utf-8\")\n",
    "gdf = gdf.rename(columns={\"Provincia\": \"province\"})\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = gpd.read_file(\"https://raw.githubusercontent.com/fcortes/Chile-GeoJSON/master/comunas.geojson\")\n",
    "# gdf.head()\n",
    "# gdf[\"Comuna\"] = gdf[\"Comuna\"].str.upper().str.normalize(\"NFKD\").str.encode(\"ascii\", errors=\"ignore\").str.decode(\"utf-8\")\n",
    "# gdf = gdf.rename(columns={\"Comuna\": \"commune\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"data_output/{country}/{year}_divisiveness_{location_level}.csv.gz\", compression=\"gzip\")\n",
    "\n",
    "if location_level == \"province\":\n",
    "    df[\"province\"] = df[\"province\"].replace({\n",
    "        \"BIOBIO\": \"BIO-BIO\",\n",
    "        \"CHAÑARAL\": \"CHANARAL\",\n",
    "        \"DEL TAMARUGAL\": \"TAMARUGAL\",\n",
    "        \"SAN FELIPE DE ACONCAGUA\": \"SAN FELIPE\"\n",
    "    })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df_fround[location_level].unique()) - set(gdf[location_level].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(gdf[location_level].unique()) - set(df_fround[location_level].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(f\"data_output/{country}/{year}_first_round.csv.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fround = pd.read_csv(f\"data_output/{country}/{year}_first_round.csv.gz\", compression=\"gzip\")\n",
    "df_fround.columns = [x.lower() for x in df_fround.columns]\n",
    "\n",
    "df_runoff = pd.read_csv(f\"data_output/{country}/{year}_runoff.csv.gz\", compression=\"gzip\")\n",
    "df_runoff.columns = [x.lower() for x in df_runoff.columns]\n",
    "\n",
    "candidate_a, candidate_b = df_runoff.candidate.unique()\n",
    "df_location = pd.read_csv(f\"data_output/{country}/{year}_first_round_location.csv.gz\", compression=\"gzip\")\n",
    "\n",
    "df_fround = pd.merge(df_fround, df_location, on=\"polling_id\")\n",
    "df_runoff = pd.merge(df_runoff, df_location, on=\"polling_id\")\n",
    "\n",
    "if location_level == \"province\":\n",
    "    df_fround[\"province\"] = df_fround[\"province\"].replace({\n",
    "        \"BIOBIO\": \"BIO-BIO\",\n",
    "        \"CHAÑARAL\": \"CHANARAL\",\n",
    "        \"DEL TAMARUGAL\": \"TAMARUGAL\",\n",
    "        \"SAN FELIPE DE ACONCAGUA\": \"SAN FELIPE\"\n",
    "    })\n",
    "    \n",
    "    df_runoff[\"province\"] = df_runoff[\"province\"].replace({\n",
    "        \"BIOBIO\": \"BIO-BIO\",\n",
    "        \"CHAÑARAL\": \"CHANARAL\",\n",
    "        \"DEL TAMARUGAL\": \"TAMARUGAL\",\n",
    "        \"SAN FELIPE DE ACONCAGUA\": \"SAN FELIPE\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(gdf, df, on=location_level)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 20))\n",
    "\n",
    "data_tmp = data[data[\"candidate\"] == \"JOSE ANTONIO KAST RIST\"]\n",
    "data_tmp = data_tmp[~data_tmp[\"province\"].isin([\"ISLA DE PASCUA\", \"JUAN FERNANDEZ\"])]\n",
    "data_tmp.plot(\n",
    "    column=\"value\", cmap=\"plasma\", ax=ax, legend=True,\n",
    "             legend_kwds=dict(\n",
    "     shrink=0.3\n",
    "    ))\n",
    "\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fround[\"rank\"] = df_fround.groupby([location_level, \"candidate\"]).agg({\"value\": \"sum\"}).groupby(level=0)[\"value\"].rank(ascending=False).astype(int)\n",
    "#df_fround.groupby(location_level)[\"value\"].rank(ascending=False).astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), dpi=100)\n",
    "dd = df_runoff.groupby([location_level, \"candidate\"]).agg({\"value\": \"sum\"})\n",
    "dd[\"rank\"] = dd.groupby(level=0)[\"value\"].rank(ascending=False).astype(int)\n",
    "dd = dd.reset_index()\n",
    "\n",
    "data_tmp = dd[dd[\"rank\"] == 1]\n",
    "data_tmp = pd.merge(data_tmp, gdf, on=location_level)\n",
    "data_tmp = data_tmp[~data_tmp[\"province\"].isin([\"ISLA DE PASCUA\", \"JUAN FERNANDEZ\"])]\n",
    "data_tmp[\"color\"] = data_tmp[\"candidate\"].replace(colors)\n",
    "\n",
    "data_tmp = gpd.GeoDataFrame(data_tmp)\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "# data_tmp[\"value\"] = NormalizeData(data_tmp[\"value\"])\n",
    "\n",
    "data_tmp.plot(\n",
    "    column=\"candidate\",\n",
    "    color=data_tmp[\"color\"],\n",
    "    edgecolor=\"black\",\n",
    "    lw=0.2,\n",
    "    ax=ax, \n",
    "    legend=True, \n",
    "    legend_kwds=dict(\n",
    "#         shrink=0.3\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rank\"] = df.groupby(location_level)[\"value\"].rank(ascending=False).astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), dpi=100)\n",
    "\n",
    "data_tmp = df[df[\"rank\"] == 1]\n",
    "data_tmp = pd.merge(data_tmp, gdf, on=location_level)\n",
    "data_tmp = data_tmp[~data_tmp[\"province\"].isin([\"ISLA DE PASCUA\", \"JUAN FERNANDEZ\"])]\n",
    "data_tmp[\"color\"] = data_tmp[\"candidate\"].replace(colors)\n",
    "\n",
    "data_tmp = gpd.GeoDataFrame(data_tmp)\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "# data_tmp[\"value\"] = NormalizeData(data_tmp[\"value\"])\n",
    "\n",
    "data_tmp.plot(\n",
    "    column=\"candidate\",\n",
    "    color=data_tmp[\"color\"],\n",
    "    edgecolor=\"black\",\n",
    "    lw=0.2,\n",
    "    ax=ax, \n",
    "    legend=True, \n",
    "    legend_kwds=dict(\n",
    "#         shrink=0.3\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# where some data has already been plotted to ax\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "for key in colors.keys():\n",
    "    if key in df[\"candidate\"].unique():\n",
    "        value = colors[key]\n",
    "        patch = mpatches.Patch(color=value, label=key)\n",
    "        handles.append(patch) \n",
    "        \n",
    "legend = plt.legend(handles=handles, loc='lower center', fontsize=24, frameon=False, ncol=len(handles))\n",
    "\n",
    "def export_legend(legend, filename=\"legend.png\"):\n",
    "    fig  = legend.figure\n",
    "    fig.canvas.draw()\n",
    "    bbox  = legend.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "    # fig.savefig(filename, dpi=\"figure\", bbox_inches=bbox)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "# export_legend(legend)\n",
    "# plt.show()\n",
    "legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Imports\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# where some data has already been plotted to ax\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# manually define a new patch \n",
    "patch = mpatches.Patch(color='grey', label='Manual Label')\n",
    "\n",
    "# handles is a list, so append manual patch\n",
    "handles.append(patch) \n",
    "\n",
    "# plot the legend\n",
    "plt.legend(handles=handles, loc='upper center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endorsements = {\n",
    "    \"JOSE ANTONIO KAST RIST\": [(\"SEBASTIAN SICHEL RAMIREZ\", \"FRANCO PARISI FERNANDEZ\"), ()],\n",
    "    \"GABRIEL BORIC FONT\": [(\"MARCO ENRIQUEZ-OMINAMI GUMUCIO\", \"YASNA PROVOSTE CAMPILLAY\"), ()]\n",
    "}\n",
    "\n",
    "aa = df_fround[df_fround[\"candidate\"].isin(endorsements[candidate_a][0])].groupby(\"polling_id\").agg({\"rate\": \"sum\"})\n",
    "aa = aa.reset_index()\n",
    "aa = aa.rename(columns={\"rate\": candidate_a})\n",
    "\n",
    "bb = df_fround[df_fround[\"candidate\"].isin(endorsements[candidate_b][0])].groupby(\"polling_id\").agg({\"rate\": \"sum\"})\n",
    "bb = bb.reset_index()\n",
    "bb = bb.rename(columns={\"rate\": candidate_b})\n",
    "\n",
    "\n",
    "df_endorsement = pd.merge(aa, bb, on=\"polling_id\")\n",
    "df_endorsement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = df_fround.groupby(\"polling_id\").agg({\"value\": \"sum\"}).reset_index()\n",
    "bb = df_runoff.groupby(\"polling_id\").agg({\"value\": \"sum\"}).reset_index()\n",
    "cc = df_location.groupby(\"polling_id\").agg({\"voters\": \"sum\"}).reset_index()\n",
    "aa = pd.merge(aa, cc, on=\"polling_id\")\n",
    "aa[\"participation\"] = aa[\"value\"] / aa[\"voters\"]\n",
    "bb = pd.merge(bb, cc, on=\"polling_id\")\n",
    "bb[\"participation\"] = bb[\"value\"] / bb[\"voters\"]\n",
    "cc = pd.merge(aa, bb, on=\"polling_id\")\n",
    "cc[\"diff_participation\"] = cc[\"participation_y\"] - cc[\"participation_x\"]\n",
    "cc[\"increase_participation\"] = cc[\"diff_participation\"] > 0\n",
    "cc[\"increase_participation\"] = cc[\"increase_participation\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.increase_participation.sum()\n",
    "cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.merge(df_fround, df_runoff, on=[\"polling_id\", \"candidate\"])\n",
    "dd = dd.pivot_table(index=\"polling_id\", columns=[\"candidate\"], values=[\"rate_x\", \"rate_y\"])\n",
    "dd = dd.reset_index()\n",
    "dd.columns = [f\"{a}{b}\" for a, b in dd.columns]\n",
    "\n",
    "dd[\"winner\"] = dd.apply(lambda x: \\\n",
    "                        candidate_a if x[f\"rate_x{candidate_a}\"] > x[f\"rate_x{candidate_b}\"] else candidate_b, axis=1)\n",
    "dd[\"loser\"] = dd.apply(lambda x: \\\n",
    "                        candidate_a if x[f\"rate_x{candidate_a}\"] < x[f\"rate_x{candidate_b}\"] else candidate_b, axis=1)\n",
    "\n",
    "dd[\"rate_winner\"] = dd.apply(lambda x: \\\n",
    "                        x[f\"rate_x{candidate_a}\"] if x[f\"rate_x{candidate_a}\"] > x[f\"rate_x{candidate_b}\"] else x[f\"rate_x{candidate_b}\"], axis=1)\n",
    "dd[\"rate_loser\"] = dd.apply(lambda x: \\\n",
    "                        x[f\"rate_x{candidate_a}\"] if x[f\"rate_x{candidate_a}\"] < x[f\"rate_x{candidate_b}\"] else x[f\"rate_x{candidate_b}\"], axis=1)\n",
    "\n",
    "dd = pd.merge(dd, df_location, on=\"polling_id\")\n",
    "\n",
    "dd = pd.merge(dd, df[[\"value\", \"candidate\", location_level]].rename(columns={\"value\": \"dv_winner\"}), \n",
    "              left_on=[location_level, \"winner\"], right_on=[location_level, \"candidate\"])\n",
    "dd = pd.merge(dd, df.rename(columns={\"value\": \"dv_loser\"}), \n",
    "    left_on=[location_level, \"loser\"], right_on=[location_level, \"candidate\"])\n",
    "dd = pd.merge(dd, df_endorsement, on=\"polling_id\")\n",
    "\n",
    "dd[\"en_winner\"] = dd.apply(lambda x: \\\n",
    "                        x[candidate_a] if x[f\"rate_x{candidate_a}\"] > x[f\"rate_x{candidate_b}\"] else x[candidate_b], axis=1)\n",
    "dd[\"en_loser\"] = dd.apply(lambda x: \\\n",
    "                        x[candidate_a] if x[f\"rate_x{candidate_a}\"] < x[f\"rate_x{candidate_b}\"] else x[candidate_b], axis=1)\n",
    "\n",
    "dd[\"dv_diff\"] = dd[\"dv_winner\"] - dd[\"dv_loser\"]\n",
    "dd[\"rate_diff\"] = dd[\"rate_winner\"] - dd[\"rate_loser\"]\n",
    "\n",
    "dd[\"flip\"] = ((dd[f\"rate_x{candidate_a}\"] > dd[f\"rate_x{candidate_b}\"]) & (dd[f\"rate_y{candidate_a}\"] < dd[f\"rate_y{candidate_b}\"])) |\\\n",
    "    ((dd[f\"rate_x{candidate_b}\"] > dd[f\"rate_x{candidate_a}\"]) & (dd[f\"rate_y{candidate_b}\"] < dd[f\"rate_y{candidate_a}\"]))\n",
    "\n",
    "# dd = pd.merge(dd, ee, on=[location_level])\n",
    "dd[\"flip\"] = dd[\"flip\"].astype(int)\n",
    "dd = pd.merge(\n",
    "    dd, \n",
    "    dd.groupby(location_level).agg({\"flip\": \"mean\"}).reset_index().rename(columns={\"flip\": \"flip_neighbors\"}),\n",
    "    on=location_level\n",
    ")\n",
    "# dd = pd.merge(dd, cc[[\"polling_id\", \"diff_participation\", \"increase_participation\"]], on=\"polling_id\")\n",
    "dd.to_csv(\"test2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_curation import flip_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_df(\n",
    "    df_fround,\n",
    "    df_runoff,\n",
    "    df_location,\n",
    "    df,\n",
    "    country,\n",
    "    year,\n",
    "    location_level\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = dd.copy()\n",
    "# df_test[\"qdv_winner\"] = pd.qcut(df_test[\"dv_winner\"], 6).astype(str)\n",
    "# df_test[\"qdv_loser\"] = pd.qcut(df_test[\"dv_loser\"], 6).astype(str)\n",
    "# m = df_test.groupby([\"qdv_winner\", \"qdv_loser\"]).agg({\"flip\": \"mean\"}).reset_index()\n",
    "# m = m.pivot(index=\"qdv_winner\", columns=\"qdv_loser\", values=\"flip\")\n",
    "\n",
    "# sns.set(font_scale=2)\n",
    "# fig, ax = plt.subplots(figsize=(9.5, 8))\n",
    "# g = sns.heatmap(m, cmap=\"plasma\")\n",
    "# g.invert_yaxis()\n",
    "# g.set_xlabel(\"Divisiveness (%) Winner\")\n",
    "# g.set_ylabel(\"Divisiveness (%) Loser\")\n",
    "# g.set_xticklabels([])\n",
    "# g.set_yticklabels([])\n",
    "# g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = dd.copy().dropna()\n",
    "# df_test[\"qdv_winner\"] = pd.qcut(df_test[\"rate_winner\"], 10).astype(str)\n",
    "# df_test[\"qdv_loser\"] = pd.qcut(df_test[\"rate_loser\"], 10).astype(str)\n",
    "# m = df_test.groupby([\"qdv_winner\", \"qdv_loser\"]).agg({\"flip\": \"mean\"}).reset_index()\n",
    "# m = m.pivot(index=\"qdv_winner\", columns=\"qdv_loser\", values=\"flip\")\n",
    "\n",
    "# sns.set(font_scale=2)\n",
    "# fig, ax = plt.subplots(figsize=(9.5, 8))\n",
    "# g = sns.heatmap(m, cmap=\"plasma\")\n",
    "# g.invert_yaxis()\n",
    "# g.set_xlabel(\"Rate (%) Winner\")\n",
    "# g.set_ylabel(\"Rate (%) Loser\")\n",
    "# g.set_xticklabels([])\n",
    "# g.set_yticklabels([])\n",
    "# g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo = pd.read_excel(\n",
    "    \"https://repositoriodeis.minsal.cl/ContenidoSitioWeb2020/uploads/2019/11/DPA2018.xls\",\n",
    "    header=1\n",
    ")\n",
    "values = {\n",
    "    \"Código Comuna desde 2018\": \"commune_id\",\n",
    "    \"Nombre Comuna\": \"commune\",\n",
    "    \"Código Provincia desde 2018\": \"province_id\",\n",
    "    \"Provincia desde 2018\": \"province\",\n",
    "    \"Código Región desde 2018\": \"region_id\",\n",
    "    \"Nombre Región desde 2018\": \"region\"\n",
    "}\n",
    "df_geo = df_geo.rename(columns=values)\n",
    "df_geo = df_geo[values.values()]\n",
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poverty = pd.read_excel(\"data_external/Chile/poverty_2020.xlsx\", header=2)\n",
    "df_poverty = df_poverty[~df_poverty[\"Nombre comuna\"].isna()]\n",
    "# df_poverty = df_poverty.rename(columns={\"Nombre comuna\": \"commune\", \"Porcentaje de personas en situación de pobreza por ingresos 2020\": \"poverty_rate\"})\n",
    "# df_poverty[\"commune\"] = df_poverty[\"commune\"].apply(lambda x: x.upper())\n",
    "df_poverty = df_poverty.rename(columns={\n",
    "    \"Nombre comuna\": \"commune\", \n",
    "    \"Código\": \"commune_id\",\n",
    "    \"Número de personas según proyecciones de población (*)\": \"population\",\n",
    "    \"Número de personas en situación de pobreza por ingresos (**)\": \"poverty\",\n",
    "    \"Porcentaje de personas en situación de pobreza por ingresos 2020\": \"poverty_rate\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.merge(df_geo, df_poverty[[\"commune_id\", \"population\", \"poverty\"]], on=\"commune_id\")\n",
    "tmp = tmp.groupby(\"province\").agg({\"population\": \"sum\", \"poverty\": \"sum\"})\n",
    "tmp[\"poverty_rate\"] = tmp[\"poverty\"] / tmp[\"population\"]\n",
    "tmp = tmp.reset_index()\n",
    "tmp[\"province\"] = tmp[\"province\"].str.upper()\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_tmp = df.groupby(\"province\").agg({\"value\": \"mean\"}).reset_index()\n",
    "data = pd.merge(df_tmp, tmp, on=\"province\")\n",
    "# data = pd.merge(data, df_location[[\"province\", \"province_id\"]].drop_duplicates(), on=\"department\")\n",
    "import numpy as np\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "# data_tmp[\"value\"] = NormalizeData(data_tmp[\"value\"])\n",
    "\n",
    "data[\"value\"] = NormalizeData(data[\"value\"])\n",
    "sns.set(font_scale=2, style=\"white\")\n",
    "fig, ax = plt.subplots(figsize=(9, 9), dpi=100)\n",
    "\n",
    "x = \"poverty_rate\"\n",
    "y = \"value\"\n",
    "\n",
    "corr, _ = pearsonr(data[x], data[y])\n",
    "p_value = \"{:0.3e}\".format(_)\n",
    "\n",
    "# plt.legend([], [], loc=2, title=f\"R²={(corr*corr*100).round(1)}%\\np-value={p_value}\", frameon=False)\n",
    "FONT_SIZE = 18\n",
    "ax.text(\n",
    "    0.035, 0.95, \n",
    "           f\"Pearson correlation = {(corr).round(3)}\", ha=\"left\", va=\"center\", fontsize=FONT_SIZE, \n",
    "           transform=ax.transAxes)\n",
    "ax.text(0.035, 0.9, \n",
    "       f\"p-value = {p_value}\", ha=\"left\", va=\"center\", fontsize=FONT_SIZE, \n",
    "       transform=ax.transAxes)\n",
    "\n",
    "sns.scatterplot(x=\"poverty_rate\", s=80, lw=0, y=\"value\", data=data, ax=ax, color=\"#138303\")\n",
    "\n",
    "ax.set_xlabel(\"Poverty Rate (%)\")\n",
    "ax.set_ylabel(\"Divisiveness (Normalized)\")\n",
    "\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "\n",
    "# texts = []\n",
    "# for x, tmp in data.iterrows():\n",
    "#     texts.append(ax.text(tmp[\"poverty_rate\"], tmp[\"value\"], tmp[\"department_id\"], fontsize=16, color=\"#444444\"))\n",
    "    \n",
    "# adjust_text(texts, lim=200, ax=ax, arrowprops=dict(arrowstyle=\"-\", color=\"#766596\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dv_a = pd.read_csv(f\"data_output/{country}/2017_divisiveness_{location_level}.csv.gz\", compression=\"gzip\") #_{rnd}\n",
    "# df_dv_a = pd.merge(df_dv_a, df_location[[\"department_id\", \"department\"]], on=location_level)\n",
    "\n",
    "\n",
    "df_dv_b = pd.read_csv(f\"data_output/{country}/2021_divisiveness_{location_level}.csv.gz\", compression=\"gzip\") #_{rnd}\n",
    "# df_dv_b = pd.merge(df_dv_b, df_location[[\"department_id\", \"department\"]], on=location_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = pd.merge(\n",
    "    df_dv_a.groupby(location_level).agg({\"value\": \"mean\"}).reset_index(), \n",
    "    df_dv_b.groupby(location_level).agg({\"value\": \"mean\"}).reset_index(),\n",
    "    on=location_level\n",
    ")\n",
    "gdf2 = pd.merge(gdf, cc, on=location_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gdf2[[\"value_x\", \"value_y\", \"averaged_values_x\", \"averaged_values_y\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal\n",
    "\n",
    "# create weights\n",
    "W = libpysal.weights.Queen.from_dataframe(gdf2)\n",
    "\n",
    "# row-normalise weights\n",
    "W.transform = \"r\"\n",
    "\n",
    "# create lag\n",
    "gdf2[\"averaged_values_x\"] = libpysal.weights.lag_spatial(W, gdf2[\"value_x\"])\n",
    "gdf2[\"averaged_values_y\"] = libpysal.weights.lag_spatial(W, gdf2[\"value_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf2[[\"value_x\", \"value_y\", \"averaged_values_x\", \"averaged_values_y\"]]\\\n",
    ".to_csv(f\"data_regressions/{country}_time_lag.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
